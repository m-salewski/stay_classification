{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will reload imports before executing code, allowing you to easily change contents of custom scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stay classification: batch of synthetic training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('/home/sandm/Notebooks/stay_classification/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, 10)]\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the clusters which have a temporal gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQR-plotting\n",
    "\n",
    "For each sub-cluster, plot the quantile boxes with whistkers.\n",
    "\n",
    "**Notes**\n",
    "* the boxes usually capture the baseline of the underlying stay\n",
    "* the forward and backward clusters\n",
    "    * usually the same clusters in the stays with similar IQRs\n",
    "    * usually different in the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here\n",
    "\n",
    "At this point, it seems that the basic clusters are formed. \n",
    "\n",
    "Next, use the IQRs of these clusters as the new bounds for extending the cluster: essentially using the extensible box method.\n",
    "\n",
    "Note that the IQR can be larger than the allow distance threshold; the box would therefore need to be the smaller of the two but with the same mean and/or median\n",
    "\n",
    "### Summary\n",
    "\n",
    "1. `get_clusters_x` finds the clusters based on nearness of events in space and time\n",
    "2. `merge_clusters` merges neraby clusters based on ...\n",
    "3. `merge_clusters_2`  merges neraby clusters based on ...\n",
    "4. `extend_clusters` extend the clusters\n",
    "5. `separate_clusters` break the overlapping clusters and then re-merge\n",
    "6. `merge_clusters_2` merge the separated clusters\n",
    "7. `intersect` the forward and backward clusters\n",
    "\n",
    "### Notes\n",
    "\n",
    "Mostly, the results are good: more than 80% of the trajectories have prec and/or recall above 0.8\n",
    "\n",
    "The main issue\n",
    "* loss of precision due to non-stays being identified\n",
    "    * this (loss) is increased with higher event density but compensated by an increase in recall\n",
    "        * since many clusters are identified and the stay events have a higher probability of being classified as stay events.\n",
    "<br/>\n",
    "\n",
    "**TODO** since stay events are classified and not the accuracy of the stays, it would be useful to have a measure of the stay accuracy: _ie_ once a stay is identified, how much of that stay is correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper__3stays_v3_scripts import switch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_data.plotting import plot_trajectory, add_plot_trajectory, add_plot_seg_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper__3stays_v3_scripts__plotting import plot_cluster_boxplots, add_plot_cluster_boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper__3stays_v3_scripts__eval import get_segments_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_clusts = lambda cluster_list : [print(f\"[{c[0]:4d},{c[-1]:4d}]\") for c in cluster_list]\n",
    "#print_ctimes = lambda cluster_list : [print(f\"[{time_arr[c[0]]:6.3f},{time_arr[c[-1]]:6.3f}]\") for c in cluster_list]\n",
    "#print_ctdiff = lambda cluster_list : [print(f\"{time_arr[c[-1]] - time_arr[c[0]]:6.3f}\") for c in cluster_list]\n",
    "#print_times = lambda l: list(map(lambda x: f\"{x:6.3f}\",l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_data.trajectory import get_stay_segs, get_adjusted_stays\n",
    "#from synthetic_data.trajectory_class import get_rand_traj\n",
    "from synthetic_data.plotting import plot_trajectory, add_plot_seg_boxes\n",
    "\n",
    "from synthetic_data.trajectory_class import get_trajectory\n",
    "#from synthetic_data.trajectory import get_stay\n",
    "\n",
    "dsec = 1/3600.0\n",
    "t_total = np.arange(0,24,dsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_data.canonical_stays import get3e, get3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper__get_clusters import get_clusters_1, get_clusters_2, get_clusters_3, get_clusters_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_thresh = 1/6\n",
    "dist_thresh=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event frac. =  0.007\n",
      "Dupli. frac. =  0.300\n"
     ]
    }
   ],
   "source": [
    "rand_range = lambda min_, max_, size: (max_-min_)*np.random.random_sample(size=size) + min_\n",
    "\n",
    "event_frac = rand_range(0.01,0.001, 1)[0]\n",
    "duplicate_frac = 0.30 #rand_range(1,0.3,0.05)[0]\n",
    "\n",
    "print(f\"Event frac. = {event_frac:6.3f}\\nDupli. frac. = {duplicate_frac:6.3f}\")\n",
    "\n",
    "configs = {\n",
    "    'time_thresh':1/6,\n",
    "    'dist_thresh':0.5,\n",
    "    'event_frac':event_frac,\n",
    "    'duplicate_frac':duplicate_frac,    \n",
    "    'noise_min':0.02,\n",
    "    'noise_max':0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_stay():\n",
    "    \n",
    "    rand_range = lambda min_, max_, size: (max_-min_)*np.random.random_sample(size=size) + min_\n",
    "\n",
    "    event_frac = rand_range(0.05,0.001, 1)[0]\n",
    "    duplicate_frac = 0.30 #rand_range(1,0.3,0.05)[0]\n",
    "\n",
    "    configs = {\n",
    "        'time_thresh':1/6,\n",
    "        'dist_thresh':0.5,\n",
    "        'event_frac':event_frac,\n",
    "        'duplicate_frac':duplicate_frac,    \n",
    "        'noise_min':0.02,\n",
    "        'noise_max':0.15\n",
    "    }\n",
    "\n",
    "    x_dist = rand_range(0.52,5.0, 10)[0]    \n",
    "    x_dist = (-1)**np.random.randint(0,2,1)*x_dist\n",
    "    \n",
    "    mid_len = rand_range(0.2, 8, 10)[0]\n",
    "    shift = rand_range(-5, 5, 21)[0]\n",
    "    \n",
    "    return configs, x_dist, mid_len, shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: './testdata_training_set__canonical_3stays/'\n"
     ]
    }
   ],
   "source": [
    "from synthetic_data.trajectory_class import pickle_trajectory\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "date_tag = datetime.today().strftime('%Y%m%d')\n",
    "#data_dir = f\"./testdata_{date_tag}_4_no_iqr_and_wi_ranges_and_wi_shift/\"\n",
    "\n",
    "data_dir = f\"./testdata_training_set__canonical_3stays/\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(data_dir)\n",
    "except OSError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10 of    11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandm/Notebooks/stay_classification/src/synthetic_data/trajectory.py:159: UserWarning: the distance between the consecutive locations is within the threshold 0.5\n",
      "  warnings.warn(f\"the distance between the consecutive locations is within the threshold {dist_thresh}\")\n"
     ]
    }
   ],
   "source": [
    "total = 11\n",
    "ii = 0\n",
    "while ii < total:\n",
    "            \n",
    "    configs, x_dist, mid_len, shift = get_rand_stay()          \n",
    "\n",
    "    #if verbose: print(f\"{x_dist:6.3f}, {mid_len:6.3f}, {shift:6.3f}\")\n",
    "\n",
    "    val = np.random.randint(0,2,1)\n",
    "    if val:\n",
    "        stays = get3(x_dist, mid_len, shift)\n",
    "    else:\n",
    "        stays = get3e(x_dist, mid_len, shift)            \n",
    "\n",
    "    continuation = True\n",
    "    m = 0\n",
    "    while continuation:\n",
    "        n = 0\n",
    "        try:\n",
    "            time_arr, raw_arr, noise_arr, segments = get_trajectory(stays, t_total, configs)\n",
    "            t_segs, x_segs = get_stay_segs(get_adjusted_stays(segments, time_arr))\n",
    "            stays_tag = int((x_segs.size)/3)\n",
    "            continuation = False\n",
    "        except:\n",
    "            print(\"Failed at\",m,n)\n",
    "            if n > 10: \n",
    "                continuation = False\n",
    "            else:\n",
    "                n+=1\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        trajectory_tag = f\"trajectory{ii}_{stays_tag}stays\"\n",
    "        path_to_file =  data_dir + trajectory_tag\n",
    "        pickle_trajectory(time_arr, raw_arr, noise_arr, segments, path_to_file + \".pkl\")\n",
    "        ii+=1\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "    if ii % 10 == 0:\n",
    "        print(f\"{ii:4d} of {total:5d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for ii in range(10, 11):\n",
    "\n",
    "    stays_tag = 3\n",
    "    trajectory_tag = f\"trajectory{ii}_{stays_tag}stays\"    \n",
    "    path_to_file =  data_dir + trajectory_tag\n",
    "    \n",
    "    trajectory = pickle.load( open(path_to_file + \".pkl\", \"rb\") )    \n",
    "    \n",
    "    segments = trajectory['segments']\n",
    "    t_arr = trajectory['time_arr']\n",
    "    r_arr = trajectory['raw_locs_arr']\n",
    "    x_arr = trajectory['nse_locs_arr']\n",
    "    t_segs, x_segs = get_stay_segs(get_adjusted_stays(segments, t_arr))\n",
    "\n",
    "    ax = plot_trajectory(t_arr, r_arr, x_arr, t_segs, x_segs, dist_thresh);\n",
    "    add_plot_seg_boxes(t_segs, x_segs, dist_thresh, ax)\n",
    "    ax.set_xlim([5.75,18.25]);\n",
    "\n",
    "    ylim = [x_arr.min()-2*dist_thresh, x_arr.max()+2*dist_thresh]\n",
    "\n",
    "    plt.savefig(path_to_file + \".png\")\n",
    "    plt.close()\n",
    "    \n",
    "    if ii % 50 == 0:\n",
    "        print(f\"{ii:5d} of 1000\")\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./testdata_training_set__canonical_3stays/'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
